{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a4bba8",
   "metadata": {},
   "source": [
    "# <span style=\"color:#873600; font-family: Trebuchet MS; font-size: 80px; font-weight: bold;\">Feature Engineering</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3e81fc",
   "metadata": {},
   "source": [
    "    * Feature engineering is a ML technique that leverages data to create new variables that arenâ€™t in the training set.\n",
    "    * Goal is: simplifying and speeding up data transformations while also enhancing model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905113e5",
   "metadata": {},
   "source": [
    "# <span style=\"color:#A04000; font-family: Trebuchet MS, sans-serif; font-size: 30px; font-weight: bold;\">Feature Engineering Techniques for Machine Learning\n",
    "</span>\n",
    "\n",
    "     1. Imputation (Numerical and Categorical)\n",
    "     2. Handling Outliers (Removal, Replacing values, Capping, Discretization)\n",
    "     3. Log Transform\n",
    "     4. One-hot encoding\n",
    "     5. Scaling (Normalization, Standartization)\n",
    "     6. Binning\n",
    "      etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e377335",
   "metadata": {},
   "source": [
    " <span style=\"color:#873600; font-family: Trebuchet MS, sans-serif; font-size: 50px; font-weight: bold;\">Imputation\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd5eecc",
   "metadata": {},
   "source": [
    " <span style=\"color:#A04000; font-family: Trebuchet MS, sans-serif; font-size: 30px; font-weight: bold;\">Dropping with threshold</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45583ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    area  bedrooms  bathrooms     price\n",
      "0  100.0       3.0        7.0       NaN\n",
      "1  150.0       4.0        NaN       NaN\n",
      "2    NaN       NaN        NaN       NaN\n",
      "3  200.0       2.0        NaN  180000.0\n",
      "4    NaN       4.0        NaN  350000.0\n",
      "5  180.0       3.0        NaN  280000.0\n",
      "\n",
      "Updated DataFrame:\n",
      "    area  bedrooms     price\n",
      "0  100.0       3.0       NaN\n",
      "1  150.0       4.0       NaN\n",
      "3  200.0       2.0  180000.0\n",
      "4    NaN       4.0  350000.0\n",
      "5  180.0       3.0  280000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample housing dataset with missing values\n",
    "housing_data = pd.DataFrame({\n",
    "    'area': [100, 150, None, 200, None, 180],\n",
    "    'bedrooms': [3, 4, None, 2, 4, 3],\n",
    "    'bathrooms': [7, None, None, None, None, None],\n",
    "    'price': [None, None, None, 180000, 350000, 280000]\n",
    "})\n",
    "\n",
    "# Display the original housing_data DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(housing_data)\n",
    "\n",
    "# Set the threshold for missing value rate\n",
    "threshold = 0.7\n",
    "\n",
    "# Dropping columns with missing value rate higher than threshold\n",
    "housing_data = housing_data[housing_data.columns[housing_data.isnull().mean() < threshold]]\n",
    "\n",
    "# Dropping rows with missing value rate higher than threshold\n",
    "housing_data = housing_data.loc[housing_data.isnull().mean(axis=1) < threshold]\n",
    "\n",
    "# Display the updated housing_data DataFrame\n",
    "print(\"\\nUpdated DataFrame:\")\n",
    "print(housing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015f467b",
   "metadata": {},
   "source": [
    " <span style=\"color:#A04000; font-family: Trebuchet MS, sans-serif; font-size: 30px; font-weight: bold;\">Numerical Imputation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e4beb",
   "metadata": {},
   "source": [
    "    * Imputation is a more preferable option rather than dropping because it preserves the data size/\n",
    "    * I think the best imputation way is to use the medians of the columns, because they are more solid to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ce4baff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Math  Science  English\n",
      "0  80.0     75.0      NaN\n",
      "1  90.0      NaN     75.0\n",
      "2   NaN     85.0     80.0\n",
      "3  70.0     90.0     85.0\n",
      "4  85.0     80.0      NaN\n",
      "\n",
      "DataFrame after filling missing values with 0:\n",
      "   Math  Science  English\n",
      "0  80.0     75.0      0.0\n",
      "1  90.0      0.0     75.0\n",
      "2   0.0     85.0     80.0\n",
      "3  70.0     90.0     85.0\n",
      "4  85.0     80.0      0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample scores dataset with missing values\n",
    "scores_data = pd.DataFrame({\n",
    "    'Math': [80, 90, np.nan, 70, 85],\n",
    "    'Science': [75, np.nan, 85, 90, 80],\n",
    "    'English': [np.nan, 75, 80, 85, np.nan]\n",
    "})\n",
    "\n",
    "# Display the original scores_data DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(scores_data)\n",
    "\n",
    "# Fill missing values with 0\n",
    "scores_data = scores_data.fillna(0)\n",
    "\n",
    "# Display the DataFrame after filling missing values with 0\n",
    "print(\"\\nDataFrame after filling missing values with 0:\")\n",
    "print(scores_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2edddb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Math  Science  English\n",
      "0  80.0     75.0      NaN\n",
      "1  90.0      NaN     75.0\n",
      "2   NaN     85.0     80.0\n",
      "3  70.0     90.0     85.0\n",
      "4  85.0     80.0      NaN\n",
      "\n",
      "DataFrame after filling missing values with mean:\n",
      "   Math  Science  English\n",
      "0  80.0     75.0     80.0\n",
      "1  90.0     82.5     75.0\n",
      "2  82.5     85.0     80.0\n",
      "3  70.0     90.0     85.0\n",
      "4  85.0     80.0     80.0\n"
     ]
    }
   ],
   "source": [
    "# Create a sample scores dataset with missing values\n",
    "scores_data = pd.DataFrame({\n",
    "    'Math': [80, 90, np.nan, 70, 85],\n",
    "    'Science': [75, np.nan, 85, 90, 80],\n",
    "    'English': [np.nan, 75, 80, 85, np.nan]\n",
    "})\n",
    "\n",
    "# Display the original scores_data DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(scores_data)\n",
    "\n",
    "# Fill missing values with median of the columns\n",
    "scores_data = scores_data.fillna(scores_data.median())\n",
    "\n",
    "# Display the final DataFrame after filling missing values with medians\n",
    "print(\"\\nDataFrame after filling missing values with mean:\")\n",
    "print(scores_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe7b196",
   "metadata": {},
   "source": [
    " <span style=\"color:#A04000; font-family: Trebuchet MS, sans-serif; font-size: 30px; font-weight: bold;\">Numerical Imputation with sklearn</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "81b3c3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Math  Science  English\n",
      "0  80.0     75.0      NaN\n",
      "1  90.0      NaN     75.0\n",
      "2   NaN     85.0     80.0\n",
      "3  70.0     90.0     85.0\n",
      "4  85.0     80.0      NaN\n",
      "\n",
      "DataFrame after filling missing values with median:\n",
      "   Math  Science  English\n",
      "0  80.0     75.0     80.0\n",
      "1  90.0     82.5     75.0\n",
      "2  82.5     85.0     80.0\n",
      "3  70.0     90.0     85.0\n",
      "4  85.0     80.0     80.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create a sample scores dataset with missing values\n",
    "scores_data = pd.DataFrame({\n",
    "    'Math': [80, 90, np.nan, 70, 85],\n",
    "    'Science': [75, np.nan, 85, 90, 80],\n",
    "    'English': [np.nan, 75, 80, 85, np.nan]\n",
    "})\n",
    "\n",
    "# Display the original scores_data DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(scores_data)\n",
    "\n",
    "# Create an instance of SimpleImputer with the \"median\" strategy\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Fill missing values in the scores_data DataFrame using the imputer\n",
    "scores_data = pd.DataFrame(imputer.fit_transform(scores_data), columns=scores_data.columns)\n",
    "\n",
    "# Display the final DataFrame after filling missing values\n",
    "print(\"\\nDataFrame after filling missing values with median:\")\n",
    "print(scores_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae02060",
   "metadata": {},
   "source": [
    " <span style=\"color:#A04000; font-family: Trebuchet MS, sans-serif; font-size: 30px; font-weight: bold;\">Categorical Imputation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea2cd94",
   "metadata": {},
   "source": [
    "    * Replacing the missing values with the mode in a column is a good option for handling categorical columns.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0149e9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  Sentiment\n",
      "0  Positive\n",
      "1  Negative\n",
      "2  Positive\n",
      "3      None\n",
      "4  Positive\n",
      "5      None\n",
      "6   Neutral\n",
      "7  Positive\n",
      "\n",
      "DataFrame after filling missing values:\n",
      "  Sentiment\n",
      "0  Positive\n",
      "1  Negative\n",
      "2  Positive\n",
      "3  Positive\n",
      "4  Positive\n",
      "5  Positive\n",
      "6   Neutral\n",
      "7  Positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample feedback dataset with missing values\n",
    "feedback_data = pd.DataFrame({\n",
    "    'Sentiment': ['Positive', 'Negative', 'Positive', None, 'Positive', None, 'Neutral', 'Positive']\n",
    "})\n",
    "\n",
    "# Display the original feedback_data DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(feedback_data)\n",
    "\n",
    "# Fill missing values with the most frequent sentiment\n",
    "feedback_data['Sentiment'].fillna(feedback_data['Sentiment'].value_counts().idxmax(), inplace=True)\n",
    "\n",
    "# Display the DataFrame after filling missing values\n",
    "print(\"\\nDataFrame after filling missing values:\")\n",
    "print(feedback_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f940682",
   "metadata": {},
   "source": [
    " <span style=\"color:#A04000; font-family: Trebuchet MS, sans-serif; font-size: 30px; font-weight: bold;\">Categorical Imputation with sklearn</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5614dc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  Sentiment\n",
      "0  Positive\n",
      "1  Negative\n",
      "2  Positive\n",
      "3      None\n",
      "4  Positive\n",
      "5      None\n",
      "6   Neutral\n",
      "7  Positive\n",
      "\n",
      "DataFrame after filling missing values:\n",
      "  Sentiment\n",
      "0  Positive\n",
      "1  Negative\n",
      "2  Positive\n",
      "3  Positive\n",
      "4  Positive\n",
      "5  Positive\n",
      "6   Neutral\n",
      "7  Positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create a sample feedback dataset with missing values\n",
    "feedback_data = pd.DataFrame({\n",
    "    'Sentiment': ['Positive', 'Negative', 'Positive', None, 'Positive', None, 'Neutral', 'Positive']\n",
    "})\n",
    "\n",
    "# Display the original feedback_data DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(feedback_data)\n",
    "\n",
    "# Create an instance of SimpleImputer with the \"most_frequent\" strategy\n",
    "imputer = SimpleImputer(missing_values=None,strategy='most_frequent')\n",
    "\n",
    "# Fill missing values in the \"Sentiment\" column using the imputer\n",
    "feedback_data['Sentiment'] = imputer.fit_transform(feedback_data[['Sentiment']])\n",
    "\n",
    "# Display the DataFrame after filling missing values\n",
    "print(\"\\nDataFrame after filling missing values:\")\n",
    "print(feedback_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0259fd7",
   "metadata": {},
   "source": [
    " <span style=\"color:#873600; font-family: Trebuchet MS, sans-serif; font-size: 50px; font-weight: bold;\">Binning\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11390422",
   "metadata": {},
   "source": [
    "    * The main motivation of binning is to make the model more robust and prevent overfitting.\n",
    "    * However, it has a cost to the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff4982",
   "metadata": {},
   "source": [
    " <span style=\"color:#A04000; font-family: Trebuchet MS, sans-serif; font-size: 30px; font-weight: bold;\">Numerical Binning</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a9a5e2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   value\n",
      "0     15\n",
      "1     50\n",
      "2     80\n",
      "3     25\n",
      "4     90\n",
      "5     35\n",
      "\n",
      "DataFrame with 'bin' column:\n",
      "   value   bin\n",
      "0     15   Low\n",
      "1     50   Mid\n",
      "2     80  High\n",
      "3     25   Low\n",
      "4     90  High\n",
      "5     35   Mid\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'value': [15, 50, 80, 25, 90, 35]\n",
    "})\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(data)\n",
    "\n",
    "# Create a new column 'bin' based on value ranges\n",
    "data['bin'] = pd.cut(data['value'], bins=[0, 30, 70, 100], labels=[\"Low\", \"Mid\", \"High\"])\n",
    "\n",
    "# Display the DataFrame with the new 'bin' column\n",
    "print(\"\\nDataFrame with 'bin' column:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3014d4e",
   "metadata": {},
   "source": [
    " <span style=\"color:#A04000; font-family: Trebuchet MS, sans-serif; font-size: 30px; font-weight: bold;\">Bin continous data into intervals with sklearn</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3bd4682c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   value\n",
      "0     15\n",
      "1     50\n",
      "2     80\n",
      "3     25\n",
      "4     90\n",
      "5     35\n",
      "\n",
      "DataFrame with 'bin' column:\n",
      "   value   bin\n",
      "0     15   Low\n",
      "1     50   Mid\n",
      "2     80  High\n",
      "3     25   Low\n",
      "4     90  High\n",
      "5     35   Low\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'value': [15, 50, 80, 25, 90, 35]\n",
    "})\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(data)\n",
    "\n",
    "# Create an instance of KBinsDiscretizer\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "\n",
    "# Fit and transform the 'value' column to create bins\n",
    "bins = discretizer.fit_transform(data[['value']])\n",
    "\n",
    "# Map bin indices to labels manually\n",
    "labels = [\"Low\", \"Mid\", \"High\"]\n",
    "data['bin'] = [labels[int(bin_index)] for bin_index in bins]\n",
    "\n",
    "# Display the DataFrame with the new 'bin' column\n",
    "print(\"\\nDataFrame with 'bin' column:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3a52ea",
   "metadata": {},
   "source": [
    " <span style=\"color:#A04000; font-family: Trebuchet MS, sans-serif; font-size: 30px; font-weight: bold;\">Binarize data according to a threshold with sklearn</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c12da77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   value\n",
      "0     15\n",
      "1     50\n",
      "2     80\n",
      "3     25\n",
      "4     90\n",
      "5     35\n",
      "6     67\n",
      "\n",
      "DataFrame with 'bin' column:\n",
      "   value  bin\n",
      "0     15    0\n",
      "1     50    0\n",
      "2     80    1\n",
      "3     25    0\n",
      "4     90    1\n",
      "5     35    0\n",
      "6     67    1\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'value': [15, 50, 80, 25, 90, 35,67]\n",
    "})\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(data)\n",
    "\n",
    "# Create an instance of Binarizer with threshold=50\n",
    "binarizer = Binarizer(threshold=50)\n",
    "\n",
    "# Binarize the 'value' column\n",
    "binarized_values = binarizer.transform(data[['value']])\n",
    "\n",
    "# Create a new column 'bin' with the binarized values\n",
    "data['bin'] = binarized_values\n",
    "\n",
    "# Display the DataFrame with the new 'bin' column\n",
    "print(\"\\nDataFrame with 'bin' column:\")\n",
    "print(data)\n",
    "\n",
    "warnings.filterwarnings(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca44274c",
   "metadata": {},
   "source": [
    " <span style=\"color:#A04000; font-family: Trebuchet MS, sans-serif; font-size: 30px; font-weight: bold;\">Categorical Binning</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a7b4d971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     Country\n",
      "0      Spain\n",
      "1      Chile\n",
      "2  Australia\n",
      "3      Italy\n",
      "4     Brazil\n",
      "\n",
      "DataFrame with 'Continent' column:\n",
      "     Country      Continent\n",
      "0      Spain         Europe\n",
      "1      Chile  South America\n",
      "2  Australia          Other\n",
      "3      Italy         Europe\n",
      "4     Brazil  South America\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Country': ['Spain', 'Chile', 'Australia', 'Italy', 'Brazil']\n",
    "})\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(data)\n",
    "\n",
    "# Define the conditions for each continent\n",
    "conditions = [\n",
    "    data['Country'].str.contains('Spain'),\n",
    "    data['Country'].str.contains('Italy'),\n",
    "    data['Country'].str.contains('Chile'),\n",
    "    data['Country'].str.contains('Brazil')\n",
    "]\n",
    "\n",
    "# Define the corresponding choices for each condition\n",
    "choices = ['Europe', 'Europe', 'South America', 'South America']\n",
    "\n",
    "# Assign the continent based on the conditions and choices\n",
    "data['Continent'] = np.select(conditions, choices, default='Other')\n",
    "\n",
    "# Display the DataFrame with the new 'Continent' column\n",
    "print(\"\\nDataFrame with 'Continent' column:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a391a0",
   "metadata": {},
   "source": [
    " <span style=\"color:#873600; font-family: Trebuchet MS, sans-serif; font-size: 50px; font-weight: bold;\">Log Transform\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e4162",
   "metadata": {},
   "source": [
    "    * It helps to handle skewed data and after transformation, the distribution becomes more approximate to normal.\n",
    "    * It also decreases the effect of the outliers.\n",
    "    * The data you apply log transform must have only positive values, otherwise you receive an error.\n",
    "    * You can add 1 to your data before transform it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6d68c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log Transform Example\n",
    "data = pd.DataFrame({'value':[2,45, -23, 85, 28, 2, 35, -12]})\n",
    "data['ln(x+1)'] = (data['value']+1).transform(np.log)\n",
    "#Negative Values Handling\n",
    "#Note that the values are different\n",
    "data[' ln(x-min(x)+1)'] = (data['value']-data['value'].min()+1) .transform(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f56745f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>ln(x+1)</th>\n",
       "      <th>ln(x-min(x)+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>3.258097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>3.828641</td>\n",
       "      <td>4.234107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85</td>\n",
       "      <td>4.454347</td>\n",
       "      <td>4.691348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>3.951244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>3.258097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>4.077537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.484907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value   ln(x+1)   ln(x-min(x)+1)\n",
       "0      2  1.098612         3.258097\n",
       "1     45  3.828641         4.234107\n",
       "2    -23       NaN         0.000000\n",
       "3     85  4.454347         4.691348\n",
       "4     28  3.367296         3.951244\n",
       "5      2  1.098612         3.258097\n",
       "6     35  3.583519         4.077537\n",
       "7    -12       NaN         2.484907"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9191f9",
   "metadata": {},
   "source": [
    " <span style=\"color:#873600; font-family: Trebuchet MS, sans-serif; font-size: 50px; font-weight: bold;\">Label Encoding\n",
    "</span>\n",
    "\n",
    "    * Label encoding is a process of converting categorical variables into numerical values.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00116633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1 3 2 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample data\n",
    "categories = ['red', 'blue', 'green', 'yellow', 'red', 'blue']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categories\n",
    "encoded_categories = encoder.fit_transform(categories)\n",
    "\n",
    "# Print the encoded categories\n",
    "print(encoded_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa5d04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color  size  shape\n",
      "0      2     2      0\n",
      "1      0     1      1\n",
      "2      1     0      0\n",
      "3      3     0      1\n",
      "4      2     1      0\n",
      "5      0     2      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'color': ['red', 'blue', 'green', 'yellow', 'red', 'blue'],\n",
    "    'size': ['small', 'medium', 'large', 'large', 'medium', 'small'],\n",
    "    'shape': ['circle', 'square', 'circle', 'square', 'circle', 'square']\n",
    "})\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Iterate over each column in the DataFrame\n",
    "for column in data.columns:\n",
    "    # Check if the column data type is object (categorical)\n",
    "    if data[column].dtype == 'object':\n",
    "        # Fit and transform the column\n",
    "        data[column] = encoder.fit_transform(data[column])\n",
    "\n",
    "# Print the modified DataFrame\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b9e739",
   "metadata": {},
   "source": [
    " <span style=\"color:#873600; font-family: Trebuchet MS, sans-serif; font-size: 50px; font-weight: bold;\">One Hot Encoding\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db3a90b",
   "metadata": {},
   "source": [
    "    * This method spreads the values in a column to multiple flag columns and assigns 0 or 1 to them/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa97e67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color_blue  color_green  color_red  color_yellow  size_large  size_medium  \\\n",
      "0           0            0          1             0           0            0   \n",
      "1           1            0          0             0           0            1   \n",
      "2           0            1          0             0           1            0   \n",
      "3           0            0          0             1           1            0   \n",
      "4           0            0          1             0           0            1   \n",
      "5           1            0          0             0           0            0   \n",
      "\n",
      "   size_small  shape_circle  shape_square  \n",
      "0           1             1             0  \n",
      "1           0             0             1  \n",
      "2           0             1             0  \n",
      "3           0             0             1  \n",
      "4           0             1             0  \n",
      "5           1             0             1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'color': ['red', 'blue', 'green', 'yellow', 'red', 'blue'],\n",
    "    'size': ['small', 'medium', 'large', 'large', 'medium', 'small'],\n",
    "    'shape': ['circle', 'square', 'circle', 'square', 'circle', 'square']\n",
    "})\n",
    "\n",
    "# Perform one-hot encoding using get_dummies function\n",
    "encoded_data = pd.get_dummies(data)\n",
    "\n",
    "# Print the encoded DataFrame\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2a5fe32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  1  0  0\n",
      "1  0  1  0\n",
      "2  0  0  1\n",
      "3  1  0  0\n",
      "4  0  1  0\n",
      "5  0  0  1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "data = pd.DataFrame({'column': ['A', 'B', 'C', 'A', 'B', 'C']})\n",
    "\n",
    "# Perform one-hot encoding\n",
    "encoded_columns = pd.get_dummies(data['column'])\n",
    "\n",
    "# Join the encoded columns back to the original data and drop the original column\n",
    "data = data.join(encoded_columns).drop('column', axis=1)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af623ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color_blue  color_green  color_red  color_yellow  size_large  size_medium  \\\n",
      "0         0.0          0.0        1.0           0.0         0.0          0.0   \n",
      "1         1.0          0.0        0.0           0.0         0.0          1.0   \n",
      "2         0.0          1.0        0.0           0.0         1.0          0.0   \n",
      "3         0.0          0.0        0.0           1.0         1.0          0.0   \n",
      "4         0.0          0.0        1.0           0.0         0.0          1.0   \n",
      "5         1.0          0.0        0.0           0.0         0.0          0.0   \n",
      "\n",
      "   size_small  shape_circle  shape_square  \n",
      "0         1.0           1.0           0.0  \n",
      "1         0.0           0.0           1.0  \n",
      "2         0.0           1.0           0.0  \n",
      "3         0.0           0.0           1.0  \n",
      "4         0.0           1.0           0.0  \n",
      "5         1.0           0.0           1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'color': ['red', 'blue', 'green', 'yellow', 'red', 'blue'],\n",
    "    'size': ['small', 'medium', 'large', 'large', 'medium', 'small'],\n",
    "    'shape': ['circle', 'square', 'circle', 'square', 'circle', 'square']\n",
    "})\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Perform one-hot encoding\n",
    "encoded_data = encoder.fit_transform(data)\n",
    "\n",
    "# Create a new DataFrame with the encoded data\n",
    "encoded_df = pd.DataFrame(encoded_data.toarray(), columns=encoder.get_feature_names_out(data.columns))\n",
    "\n",
    "# Print the encoded DataFrame\n",
    "print(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6c13ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Color Size\n",
      "0    Red    S\n",
      "1  Green    M\n",
      "2   Blue    L\n",
      "3   Blue    S\n",
      "4    Red    M\n",
      "\n",
      "One-hot Encoded DataFrame:\n",
      "   Color_Green  Color_Red  Size_M  Size_S\n",
      "0            0          1       0       1\n",
      "1            1          0       1       0\n",
      "2            0          0       0       0\n",
      "3            0          0       0       1\n",
      "4            0          1       1       0\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Color': ['Red', 'Green', 'Blue', 'Blue', 'Red'],\n",
    "    'Size': ['S', 'M', 'L', 'S', 'M']\n",
    "}\n",
    "\n",
    "df_1 = pd.DataFrame(data)\n",
    "\n",
    "# Applying one-hot encoding with drop_first=True\n",
    "encoded_df = pd.get_dummies(df_1, drop_first=True)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_1)\n",
    "\n",
    "print(\"\\nOne-hot Encoded DataFrame:\")\n",
    "print(encoded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f97c8",
   "metadata": {},
   "source": [
    " <span style=\"color:#873600; font-family: Trebuchet MS, sans-serif; font-size: 50px; font-weight: bold;\">Feature Split\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719d2f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 name first_name last_name\n",
      "0  Luther N. Gonzalez     Luther  Gonzalez\n",
      "1    Charles M. Young    Charles     Young\n",
      "2        Terry Lawson      Terry    Lawson\n",
      "3       Kristen White    Kristen     White\n",
      "4      Thomas Logsdon     Thomas   Logsdon\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'name': ['Luther N. Gonzalez', 'Charles M. Young', 'Terry Lawson', 'Kristen White', 'Thomas Logsdon']\n",
    "})\n",
    "\n",
    "# Extracting first names\n",
    "data['first_name'] = data['name'].str.split(\" \").map(lambda x: x[0])\n",
    "\n",
    "# Extracting last names\n",
    "data['last_name'] = data['name'].str.split(\" \").map(lambda x: x[-1])\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36109c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title    object\n",
      "year      int32\n",
      "dtype: object\n",
      "                      title  year\n",
      "0          Toy Story (1995)  1995\n",
      "1            Jumanji (1995)  1995\n",
      "2   Grumpier Old Men (1995)  1995\n",
      "3  Waiting to Exhale (1995)  1995\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'title': ['Toy Story (1995)', 'Jumanji (1995)', 'Grumpier Old Men (1995)', 'Waiting to Exhale (1995)']\n",
    "})\n",
    "\n",
    "# Extracting the year from the title\n",
    "data['year'] = data['title'].str.split(\"(\", n=1, expand=True)[1].str.split(\")\", n=1, expand=True)[0]\n",
    "\n",
    "# Changing the data type to integer\n",
    "data['year'] = data['year'].astype(int)\n",
    "\n",
    "# Print the updated DataFrame with the corresponding data type\n",
    "print(data.dtypes)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d9bb5f",
   "metadata": {},
   "source": [
    " <span style=\"color:#873600; font-family: Trebuchet MS, sans-serif; font-size: 50px; font-weight: bold;\">Scaling\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6678991",
   "metadata": {},
   "source": [
    " <span style=\"color:#A04000; font-family: Trebuchet MS, sans-serif; font-size: 30px; font-weight: bold;\">Normalization</span>\n",
    " \n",
    "    * Normalization (or min-max normalization) scale all values in a fixed range between 0 and 1.\n",
    "    * Before normalization, it is recommended to handle the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xnorm = X - Xmin / Xmax - Xmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "682204b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2\n",
      "0      0.00      0.00\n",
      "1      0.25      0.25\n",
      "2      0.50      0.50\n",
      "3      0.75      0.75\n",
      "4      1.00      1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'feature1': [10, 20, 30, 40, 50],\n",
    "    'feature2': [5, 15, 25, 35, 45]\n",
    "})\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Perform normalization\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "# Create a new DataFrame with the normalized data\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=data.columns)\n",
    "\n",
    "# Print the normalized DataFrame\n",
    "print(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f52f67e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2\n",
      "0 -1.414214 -1.414214\n",
      "1 -0.707107 -0.707107\n",
      "2  0.000000  0.000000\n",
      "3  0.707107  0.707107\n",
      "4  1.414214  1.414214\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'feature1': [10, 20, 30, 40, 50],\n",
    "    'feature2': [5, 15, 25, 35, 45]\n",
    "})\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Perform standardization\n",
    "standardized_data = scaler.fit_transform(data)\n",
    "\n",
    "# Create a new DataFrame with the standardized data\n",
    "standardized_df = pd.DataFrame(standardized_data, columns=data.columns)\n",
    "\n",
    "# Print the standardized DataFrame\n",
    "print(standardized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acba1db",
   "metadata": {},
   "source": [
    " <span style=\"color:#A04000; font-family: Trebuchet MS, sans-serif; font-size: 30px; font-weight: bold;\">Robust Scaler</span>\n",
    " \n",
    "    * The RobustScaler uses statistics that are not influenced by outliers\n",
    "    * This Scaler removes the median and scales the data according to the quantile range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33b476bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2\n",
      "0      -1.0      -1.0\n",
      "1      -0.5      -0.5\n",
      "2       0.0       0.0\n",
      "3       0.5       0.5\n",
      "4       1.0       1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'feature1': [10, 20, 30, 40, 50],\n",
    "    'feature2': [5, 15, 25, 35, 45]\n",
    "})\n",
    "\n",
    "# Initialize RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Perform feature scaling\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Create a new DataFrame with the scaled data\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "\n",
    "# Print the scaled DataFrame\n",
    "print(scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a6c29b",
   "metadata": {},
   "source": [
    " <span style=\"color:#873600; font-family: Trebuchet MS, sans-serif; font-size: 50px; font-weight: bold;\">Extracting Date\n",
    "</span>\n",
    "\n",
    "    * Extracting the parts of the date into different columns: Year, month, day, etc\n",
    "    * Extracting the time period between the current date and columns in terms of years, months, days, etc.\n",
    "    * Extracting some specific features from the date: Name of the weekday, Weekend or not, holiday or not, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a99e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "data = pd.DataFrame({'date':\n",
    "['01-01-2017',\n",
    "'04-12-2008',\n",
    "'23-06-1988',\n",
    "'25-08-1999',\n",
    "'20-02-1993',\n",
    "]})\n",
    "\n",
    "#Transform string to date\n",
    "data['date'] = pd.to_datetime(data.date, format=\"%d-%m-%Y\")\n",
    "\n",
    "#Extracting Year\n",
    "data['year'] = data['date'].dt.year\n",
    "\n",
    "#Extracting Month\n",
    "data['month'] = data['date'].dt.month\n",
    "\n",
    "#Extracting passed years since the date\n",
    "data['passed_years'] = date.today().year - data['date'].dt.year\n",
    "\n",
    "#Extracting passed months since the date\n",
    "data['passed_months'] = (date.today().year - data['date'].dt.year) * 12 + date.today().month - data['date'].dt.month\n",
    "\n",
    "#Extracting the weekday name of the date\n",
    "data['day_name'] = data['date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c98c819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>passed_years</th>\n",
       "      <th>passed_months</th>\n",
       "      <th>day_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>78</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>175</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988-06-23</td>\n",
       "      <td>1988</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>421</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-08-25</td>\n",
       "      <td>1999</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>287</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993-02-20</td>\n",
       "      <td>1993</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>365</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  year  month  passed_years  passed_months   day_name\n",
       "0 2017-01-01  2017      1             6             78     Sunday\n",
       "1 2008-12-04  2008     12            15            175   Thursday\n",
       "2 1988-06-23  1988      6            35            421   Thursday\n",
       "3 1999-08-25  1999      8            24            287  Wednesday\n",
       "4 1993-02-20  1993      2            30            365   Saturday"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d2baca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   date           5 non-null      datetime64[ns]\n",
      " 1   year           5 non-null      int64         \n",
      " 2   month          5 non-null      int64         \n",
      " 3   passed_years   5 non-null      int64         \n",
      " 4   passed_months  5 non-null      int64         \n",
      " 5   day_name       5 non-null      object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(1)\n",
      "memory usage: 368.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5061b60",
   "metadata": {},
   "source": [
    " <span style=\"color:#873600; font-family: Trebuchet MS, sans-serif; font-size: 50px; font-weight: bold;\">Duplicates\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ac9d471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows:\n",
      "   ID  Name  Age\n",
      "4   1  John   25\n",
      "DataFrame without duplicates:\n",
      "   ID   Name  Age\n",
      "0   1   John   25\n",
      "1   2  Alice   30\n",
      "2   3    Bob   35\n",
      "3   4  Alice   30\n",
      "5   2    Bob   35\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame with duplicate values\n",
    "data = pd.DataFrame({\n",
    "    'ID': [1, 2, 3, 4, 1, 2],\n",
    "    'Name': ['John', 'Alice', 'Bob', 'Alice', 'John', 'Bob'],\n",
    "    'Age': [25, 30, 35, 30, 25, 35]\n",
    "})\n",
    "\n",
    "# Detect duplicate rows\n",
    "duplicate_rows = data.duplicated()\n",
    "\n",
    "# Print the duplicate rows\n",
    "print(\"Duplicate rows:\")\n",
    "print(data[duplicate_rows])\n",
    "\n",
    "# Drop duplicate rows\n",
    "data_without_duplicates = data.drop_duplicates()\n",
    "\n",
    "# Print the DataFrame without duplicates\n",
    "print(\"DataFrame without duplicates:\")\n",
    "print(data_without_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "448978d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    'ID': [1, 2, 3, 4, 1, 2],\n",
    "    'Name': ['John', 'Alice', 'Bob', 'Alice', 'John', 'Bob'],\n",
    "    'Age': [25, 30, 35, 30, 25, 35]\n",
    "})\n",
    "data.duplicated().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
